{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pickle #pickle序列化对象并保存到磁盘中，并在需要的时候读取出来\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "############读取所有的文件#########################\n",
    "def read_files():\n",
    "    #用户表\n",
    "    df_user = pd.read_csv(\"JData_User.csv\", encoding='gbk')\n",
    "    #商品表\n",
    "    df_product = pd.read_csv(\"JData_Product.csv\", encoding='gbk')\n",
    "    #评论表\n",
    "    df_comment = pd.read_csv(\"JData_Comment.csv\", encoding='gbk')\n",
    "    #行为表\n",
    "    df_action_1 = pd.read_csv(\"JData_Action_201602.csv\", encoding='gbk')\n",
    "    df_action_2 = pd.read_csv(\"JData_Action_201603.csv\", encoding='gbk')\n",
    "    df_action_3 = pd.read_csv(\"JData_Action_201604.csv\", encoding='gbk')\n",
    "    df_action = pd.concat([df_action_1, df_action_2, df_action_3], axis=0)\n",
    "        \n",
    "    return df_user, df_product, df_comment, df_action\n",
    "\n",
    "df_user, df_product, df_comment, df_action = read_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(user_df, product_df, comment_df, action_df):\n",
    "    \n",
    "    for df in [user_df, product_df, comment_df, action_df]:\n",
    "        print(df.dtypes)\n",
    "        print(df.head())\n",
    "        print(\"----------------\")\n",
    "\n",
    "    \n",
    "    print(\"Processing user_df...\")\n",
    "    user_df[[\"age\", \"sex\", \"user_lv_cd\"]] = user_df[[\"age\", \"sex\", \"user_lv_cd\"]].fillna(-1)\n",
    "    user_df[\"sex\"] = user_df[\"sex\"].apply(lambda value: -1 if int(value) == 2 else value)\n",
    "    user_df[\"user_reg_tm\"] = pd.to_datetime(user_df[\"user_reg_tm\"])\n",
    "    user_df[[\"user_id\", \"age\", \"sex\", \"user_lv_cd\"]] = user_df[[\"user_id\", \"age\", \"sex\", \"user_lv_cd\"]].apply(pd.to_numeric, errors='coerce').fillna(-1).astype(np.int32)\n",
    "\n",
    "    \n",
    "    print(\"Processing product_df...\")\n",
    "    product_df[[\"a1\", \"a2\", \"a3\"]] = product_df[[\"a1\", \"a2\", \"a3\"]].fillna(-1)\n",
    "    product_df[[\"sku_id\", \"a1\", \"a2\", \"a3\", \"cate\", \"brand\"]] = product_df[[\"sku_id\", \"a1\", \"a2\", \"a3\", \"cate\", \"brand\"]].astype(np.int32)\n",
    "\n",
    "    \n",
    "    print(\"Processing comment_df...\")\n",
    "    comment_df[[\"comment_num\", \"has_bad_comment\", \"bad_comment_rate\"]] = comment_df[[\"comment_num\", \"has_bad_comment\", \"bad_comment_rate\"]].fillna(0)\n",
    "    comment_df[\"dt\"] = pd.to_datetime(comment_df[\"dt\"])\n",
    "    comment_df[[\"sku_id\", \"comment_num\", \"has_bad_comment\"]] = comment_df[[\"sku_id\", \"comment_num\", \"has_bad_comment\"]].astype(np.int32)\n",
    "    comment_df[\"bad_comment_rate\"] = comment_df[\"bad_comment_rate\"].astype(np.float32)\n",
    "\n",
    "    \n",
    "    print(\"Processing action_df...\")\n",
    "    action_df[\"time\"] = action_df[\"time\"].apply(lambda t: datetime.datetime.strptime(str(t), \"%Y-%m-%d %H:%M:%S\"))\n",
    "    action_df[[\"user_id\", \"sku_id\", \"type\", \"cate\", \"brand\"]] = action_df[[\"user_id\", \"sku_id\", \"type\", \"cate\", \"brand\"]].astype(np.int32)\n",
    "\n",
    "    \n",
    "    for df in [user_df, product_df, comment_df, action_df]:\n",
    "        print(df.dtypes)\n",
    "        print(df.head())\n",
    "        print(\"----------------\")\n",
    "\n",
    "    return user_df, product_df, comment_df, action_df\n",
    "\n",
    "# # 调用函数\n",
    "# df_user, df_product, df_comment, df_action = transform_data(df_user, df_product, df_comment, df_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def save_data(df_user, df_product, df_comment, df_action):\n",
    "    if not os.path.exists(\"data.pkl\"):\n",
    "        with open(\"data.pkl\", \"wb\") as f:\n",
    "            pickle.dump((df_user, df_product, df_comment, df_action), f)\n",
    "            \n",
    "def load_data():\n",
    "    with open(\"data.pkl\", \"rb\") as f:\n",
    "        df_user, df_product, df_comment, df_action = pickle.load(f)\n",
    "    return df_user, df_product, df_comment, df_action\n",
    "\n",
    "# # 首先保存数据\n",
    "# save_data(df_user, df_product, df_comment, df_action)\n",
    "\n",
    "# 然后加载数据\n",
    "df_user, df_product, df_comment, df_action = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_users_registered_before(user_df, date_str):\n",
    "    date_threshold = pd.to_datetime(date_str)\n",
    "    filtered_users = user_df[user_df[\"user_reg_tm\"] < date_threshold]\n",
    "    return filtered_users\n",
    "\n",
    "users_registered_before_416 = fetch_users_registered_before(df_user, \"2016-04-16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exclude_users_by_registration(user_df, filtered_users):\n",
    "    valid_user_ids = filtered_users[\"user_id\"]\n",
    "    updated_user_df = user_df[user_df[\"user_id\"].isin(valid_user_ids)]\n",
    "    return updated_user_df\n",
    "\n",
    "df_user = exclude_users_by_registration(df_user, users_registered_before_416)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sku_id  a1  a2  a3  cate  brand  comment_num  has_bad_comment  \\\n",
      "0      10   3   1   1     8    489            0                0   \n",
      "1  100002   3   2   2     8    489            0                0   \n",
      "2  100003   1  -1  -1     8     30            0                0   \n",
      "3  100006   1   2   1     8    545            0                0   \n",
      "4   10001  -1   1   2     8    244            0                0   \n",
      "\n",
      "   bad_comment_rate  \n",
      "0               0.0  \n",
      "1               0.0  \n",
      "2               0.0  \n",
      "3               0.0  \n",
      "4               0.0  \n"
     ]
    }
   ],
   "source": [
    "#获取商品评论的特征，以最近的日期为准\n",
    "def extract_latest_comments_before(comment_df, date_str):\n",
    "    date_threshold = pd.to_datetime(date_str)\n",
    "    filtered_comments = comment_df[comment_df[\"dt\"] < date_threshold]\n",
    "    latest_comment_dates = filtered_comments.groupby(\"sku_id\")[\"dt\"].max().reset_index()\n",
    "    latest_comments = pd.merge(filtered_comments, latest_comment_dates, on=[\"sku_id\", \"dt\"], how=\"inner\")\n",
    "    latest_comments.drop(columns=[\"dt\"], inplace=True)\n",
    "    return latest_comments\n",
    "\n",
    "latest_comments_before_416 = extract_latest_comments_before(df_comment, \"2016-04-16\")\n",
    "\n",
    "def merge_product_with_comments(product_df, latest_comments):\n",
    "    merged_df = pd.merge(product_df, latest_comments, on=\"sku_id\", how=\"left\").fillna(0)\n",
    "    merged_df[[\"comment_num\", \"has_bad_comment\"]] = merged_df[[\"comment_num\", \"has_bad_comment\"]].astype(np.int32)\n",
    "    return merged_df\n",
    "\n",
    "df_sku = merge_product_with_comments(df_product, latest_comments_before_416)\n",
    "print(df_sku.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105309\n",
      "29485\n",
      "29483\n",
      "    user_id  age  sex  user_lv_cd user_reg_tm\n",
      "0    200001   -1   -1           5  2016-01-26\n",
      "4    200005   -1    0           4  2016-01-26\n",
      "13   200014   -1   -1           4  2013-04-10\n",
      "14   200015   -1    1           3  2016-01-26\n",
      "16   200017   -1   -1           4  2016-01-26\n"
     ]
    }
   ],
   "source": [
    "#删除所有时间段都没有购买行为的用户\n",
    "def filter_buy_users(action_df):\n",
    "    buy_actions = action_df[action_df[\"type\"] == 4]\n",
    "    unique_buy_users = buy_actions[\"user_id\"].drop_duplicates()\n",
    "    return unique_buy_users\n",
    "\n",
    "def remove_non_buyers(user_df, buy_user_ids):\n",
    "    print(len(user_df))\n",
    "    print(len(buy_user_ids))\n",
    "    filtered_users = user_df[user_df[\"user_id\"].isin(buy_user_ids)]\n",
    "    print(len(filtered_users))\n",
    "    return filtered_users\n",
    "\n",
    "buy_users = filter_buy_users(df_action)\n",
    "df_user = remove_non_buyers(df_user, buy_users)\n",
    "print(df_user.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    user_id  age  sex  user_lv_cd user_reg_tm\n",
      "0    200001   -1   -1           5  2016-01-26\n",
      "4    200005   -1    0           4  2016-01-26\n",
      "13   200014   -1   -1           4  2013-04-10\n",
      "14   200015   -1    1           3  2016-01-26\n",
      "16   200017   -1   -1           4  2016-01-26\n",
      "    sku_id  a1  a2  a3  cate  brand  comment_num  has_bad_comment  \\\n",
      "16  100119   2   1   2     8    812            1                0   \n",
      "27  100174   2   2   1     8    812            2                0   \n",
      "40  100310   3   2  -1     8    214            0                0   \n",
      "45  100344   3   1   1     8    214            0                0   \n",
      "69  100462   3   1   2     8    214            3                0   \n",
      "\n",
      "    bad_comment_rate  \n",
      "16               0.0  \n",
      "27               0.0  \n",
      "40               0.0  \n",
      "45               0.0  \n",
      "69               0.0  \n",
      "    user_id  sku_id                time  model_id  type  cate  brand\n",
      "0    266079  138778 2016-01-31 23:59:02       NaN     1     8    403\n",
      "1    266079  138778 2016-01-31 23:59:03       0.0     6     8    403\n",
      "2    200719   61226 2016-01-31 23:59:07       NaN     1     8     30\n",
      "3    200719   61226 2016-01-31 23:59:08       0.0     6     8     30\n",
      "15   266079  138778 2016-01-31 23:59:40       0.0     6     8    403\n"
     ]
    }
   ],
   "source": [
    "def del_user_sku_action_not_in_each_other(df_user, df_sku, df_action):\n",
    "    df_user_intersection = pd.merge(df_user.loc[:, \"user_id\"], df_action.loc[:, \"user_id\"], how=\"inner\", on=\"user_id\")\n",
    "    df_sku_intersection = pd.merge(df_sku.loc[:, \"sku_id\"], df_action.loc[:, \"sku_id\"], how=\"inner\", on=\"sku_id\")\n",
    "    \n",
    "    df_action = df_action.loc[(df_action.loc[:, \"sku_id\"].isin(df_sku_intersection.loc[:, \"sku_id\"])) \\\n",
    "                              & (df_action.loc[:, \"user_id\"].isin(df_user_intersection.loc[:, \"user_id\"]))]\n",
    "    df_user = df_user.loc[df_user.loc[:, \"user_id\"].isin(df_action.loc[:, \"user_id\"])]\n",
    "    df_sku = df_sku.loc[df_sku.loc[:, \"sku_id\"].isin(df_action.loc[:, \"sku_id\"])]\n",
    "    return df_user, df_sku, df_action\n",
    "df_user, df_sku, df_action = del_user_sku_action_not_in_each_other(df_user, df_sku, df_action)\n",
    "print(df_user.head())\n",
    "print(df_sku.head())\n",
    "print(df_action.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    user_id  age  sex  user_lv_cd user_reg_tm\n",
      "0    200001   -1   -1           5  2016-01-26\n",
      "4    200005   -1    0           4  2016-01-26\n",
      "13   200014   -1   -1           4  2013-04-10\n",
      "14   200015   -1    1           3  2016-01-26\n",
      "16   200017   -1   -1           4  2016-01-26\n",
      "    sku_id  a1  a2  a3  cate  brand  comment_num  has_bad_comment  \\\n",
      "16  100119   2   1   2     8    812            1                0   \n",
      "27  100174   2   2   1     8    812            2                0   \n",
      "40  100310   3   2  -1     8    214            0                0   \n",
      "45  100344   3   1   1     8    214            0                0   \n",
      "69  100462   3   1   2     8    214            3                0   \n",
      "\n",
      "    bad_comment_rate  \n",
      "16               0.0  \n",
      "27               0.0  \n",
      "40               0.0  \n",
      "45               0.0  \n",
      "69               0.0  \n",
      "    user_id  sku_id                time  model_id  type  cate  brand\n",
      "0    266079  138778 2016-01-31 23:59:02       NaN     1     8    403\n",
      "1    266079  138778 2016-01-31 23:59:03       0.0     6     8    403\n",
      "2    200719   61226 2016-01-31 23:59:07       NaN     1     8     30\n",
      "3    200719   61226 2016-01-31 23:59:08       0.0     6     8     30\n",
      "15   266079  138778 2016-01-31 23:59:40       0.0     6     8    403\n"
     ]
    }
   ],
   "source": [
    "def sync_user_sku_actions(user_df, sku_df, action_df):\n",
    "    valid_user_ids = pd.merge(user_df[[\"user_id\"]], action_df[[\"user_id\"]], on=\"user_id\", how=\"inner\")[\"user_id\"]\n",
    "    valid_sku_ids = pd.merge(sku_df[[\"sku_id\"]], action_df[[\"sku_id\"]], on=\"sku_id\", how=\"inner\")[\"sku_id\"]\n",
    "    \n",
    "    filtered_actions = action_df[action_df[\"user_id\"].isin(valid_user_ids) & action_df[\"sku_id\"].isin(valid_sku_ids)]\n",
    "    synced_users = user_df[user_df[\"user_id\"].isin(filtered_actions[\"user_id\"])]\n",
    "    synced_skus = sku_df[sku_df[\"sku_id\"].isin(filtered_actions[\"sku_id\"])]\n",
    "    \n",
    "    return synced_users, synced_skus, filtered_actions\n",
    "\n",
    "df_user, df_sku, df_action = sync_user_sku_actions(df_user, df_sku, df_action)\n",
    "print(df_user.head())\n",
    "print(df_sku.head())\n",
    "print(df_action.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29430\n",
      "3403\n",
      "6589539\n"
     ]
    }
   ],
   "source": [
    "print(len(df_user))\n",
    "print(len(df_sku))\n",
    "print(len(df_action))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(df_user, df_sku, df_action, filename):\n",
    "    if not os.path.exists(filename):\n",
    "        with open(filename, \"wb\") as f:\n",
    "            pickle.dump((df_user, df_sku, df_action), f)\n",
    "            \n",
    "def load_data(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        df_user, df_sku, df_action = pickle.load(f)\n",
    "    return df_user, df_sku, df_action\n",
    "\n",
    "save_data(df_user, df_sku, df_action, \"clean_data_without_no_buy.pkl\")\n",
    "df_user, df_sku, df_action = load_data(\"clean_data_without_no_buy.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 驱动器 D 中的卷是 Data\n",
      " 卷的序列号是 AC3C-F51C\n",
      "\n",
      " D:\\Python_jupyter\\JData高需用户购买预测 的目录\n",
      "\n",
      "2024/12/15  21:08    <DIR>          .\n",
      "2024/12/04  22:02    <DIR>          ..\n",
      "2024/12/15  21:01    <DIR>          .ipynb_checkpoints\n",
      "2024/11/18  09:11       185,446,670 clean_data_without_no_buy.pkl\n",
      "2024/11/18  09:09     2,243,573,361 data.pkl\n",
      "2024/12/15  21:08            21,735 data_clean.ipynb\n",
      "2024/11/28  17:42           188,063 data_gen_feature_and_train.ipynb\n",
      "2024/12/15  21:00           322,044 data_visualization.ipynb\n",
      "2024/12/15  21:07           153,340 data_visualization_plotly.ipynb\n",
      "2024/11/18  09:55     2,407,392,464 df_dataset.pkl\n",
      "2024/12/15  21:06    <DIR>          figs\n",
      "2017/04/03  19:03       521,876,452 JData_Action_201602.csv\n",
      "2017/04/03  19:05     1,177,389,078 JData_Action_201603.csv\n",
      "2017/04/03  19:04       600,610,318 JData_Action_201604.csv\n",
      "2017/04/03  20:23        14,849,315 JData_Comment.csv\n",
      "2017/04/03  20:34           452,506 JData_Product.csv\n",
      "2017/04/03  17:23         3,089,469 JData_User.csv\n",
      "2024/11/18  13:09           309,513 model.cb\n",
      "2024/11/18  13:55       321,441,333 model.zip\n",
      "2024/11/18  12:55           238,465 xgb_model\n",
      "              16 个文件  7,477,354,126 字节\n",
      "               4 个目录 41,070,567,424 可用字节\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id       int32\n",
       "age           int32\n",
       "sex           int32\n",
       "user_lv_cd    int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sku_id                int64\n",
       "a1                    int64\n",
       "a2                    int64\n",
       "a3                    int64\n",
       "cate                  int64\n",
       "brand                 int64\n",
       "comment_num           int32\n",
       "has_bad_comment       int32\n",
       "bad_comment_rate    float32\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sku.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>sku_id</th>\n",
       "      <th>comment_num</th>\n",
       "      <th>has_bad_comment</th>\n",
       "      <th>bad_comment_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>10000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>100011</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>100018</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>100020</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dt  sku_id  comment_num  has_bad_comment  bad_comment_rate\n",
       "0 2016-02-01    1000            3                1            0.0417\n",
       "1 2016-02-01   10000            2                0            0.0000\n",
       "2 2016-02-01  100011            4                1            0.0376\n",
       "3 2016-02-01  100018            3                0            0.0000\n",
       "4 2016-02-01  100020            3                0            0.0000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_comment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
